name: Generate IP Lists - Upload to CloudFlare

on:
  schedule:
    # Runs once a day at midnight
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  generate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: awalsh128/cache-apt-pkgs-action@latest
        with:
          packages: whois
          version: 1.0

      - name: Generate GoogleBot IP-List
        run: curl -sL https://developers.google.com/static/search/apis/ipranges/googlebot.json | jq -r '.prefixes[].ipv6Prefix,.prefixes[].ipv4Prefix | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/googlebot.ips
 
      - name: Generate BingBot IP-List
        run: curl -sL https://www.bing.com/toolbox/bingbot.json | jq -r '.prefixes[].ipv6Prefix,.prefixes[].ipv4Prefix | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/bingbot.ips

      - name: Generate Common Crwal Bot IP-List
        run: curl -sL https://index.commoncrawl.org/ccbot.json | jq -r '.prefixes[].ipv6Prefix,.prefixes[].ipv4Prefix | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/commoncrawlbot.ips

      - name: Generate AppleBot IP-List
        run: curl -sL https://search.developer.apple.com/applebot.json | jq -r '.prefixes[].ipv6Prefix,.prefixes[].ipv4Prefix | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/applebot.ips

      - name: Generate Fastly IP-List
        run: curl -sL https://api.fastly.com/public-ip-list | jq -r '.ipv6_addresses[],.addresses[] | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/fastly.ips

 #     - name: Generate AhrefsBot IP-List # Source: https://help.ahrefs.com/en/articles/78658-what-is-the-list-of-your-ip-ranges
 #       run: curl -sL https://api.ahrefs.com/v3/public/crawler-ips | jq -r '.ips[].ip_address | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/ahrefsbot.ips
        
      - name: Generate FacebookBot IP-List # Source: https://developers.facebook.com/docs/sharing/webmasters/crawler/
        run: whois -h whois.radb.net -- '-i origin AS32934' | grep ^route | awk '{gsub("(route:|route6:)","");print}' | awk '{gsub(/ /,""); print}' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/facebookbot.ips
     
      - name: Generate DuckDuckBot IP-List # Source: https://help.duckduckgo.com/duckduckgo-help-pages/results/duckduckbot/
        run: curl -sL https://raw.githubusercontent.com/duckduckgo/duckduckgo-help-pages/master/_docs/results/duckduckbot.md | grep "^\- " | awk '{gsub("-",""); print}' | awk '{gsub(/ /,""); print}' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/duckduckbot.ips
      
      - name: Get Telegram IP List
        run: curl -sL https://core.telegram.org/resources/cidr.txt | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/telegrambot.ips

      - name: Get UptimeRobot IP List # Source: https://uptimerobot.com/help/locations/
        run: curl -sL https://uptimerobot.com/inc/files/ips/IPv4andIPv6.txt | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/uptimerobot.ips

      - name: Get Pingdom IP List # Source: https://documentation.solarwinds.com/en/success_center/pingdom/content/topics/pingdom-probe-servers-ip-addresses.htm
        run: |
          curl -sL https://my.pingdom.com/probes/ipv4 | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/pingdombot.ips
          curl -sL https://my.pingdom.com/probes/ipv6 | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh >> $GITHUB_WORKSPACE/iplists-botsonly/pingdombot.ips
      
      - name: Get Stripe Webhook IP List # Source: https://stripe.com/docs/ips
        run: curl -sL https://stripe.com/files/ips/ips_webhooks.txt | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/stripewebhook.ips
        
      - name: Get RSS API IP List # Source: https://rssapi.net/faq
        run: curl -sL https://rssapi.net/ips.txt | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/rssapi.ips

      - name: Get BetterUptime IP List # Source: https://docs.betteruptime.com/frequently-asked-questions
        run: curl -sL https://betteruptime.com/ips.txt | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/betteruptimebot.ips
        
      - name: Generate WebpagetestBot IP-List # Source: https://www.webpagetest.org/addresses.php
        run: curl -sL https://www.webpagetest.org/addresses.php?f=json | jq -r '.data[].addresses[] | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/webpagetestbot.ips
        
      - name: Get BunnyCDN IP List # Source: https://support.bunny.net/hc/en-us/articles/115001131172-I-am-seeing-a-lot-of-502-and-504-errors
        run: |
          curl -sL https://api.bunny.net/system/edgeserverlist/plain | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/bunnycdn.ips
          curl -sL https://api.bunny.net/system/edgeserverlist/ipv6 | jq -r '.[] | select( . != null )' | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh >> $GITHUB_WORKSPACE/iplists-botsonly/bunnycdn.ips
          
 #     - name: Get Cloudflare IP List # Source: https://www.cloudflare.com/ips/
 #       run: |
 #         curl -sL https://www.cloudflare.com/ips-v4 | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips
 #         echo "" >> $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips # join lists with new line (will be filtered out later)
 #         curl -sL https://www.cloudflare.com/ips-v6 | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh >> $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips
 #         cat $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips.tmp
 #         mv $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips.tmp $GITHUB_WORKSPACE/iplists-botsonly/cloudflare.ips

      - name: Create merged/total IP-List (all.ips) # Use grep to merge files and ensure proper new-lines between every file, but remove any empty new-lines
        run: grep -h -v '^[[:space:]]*$' $GITHUB_WORKSPACE/iplists-botsonly/*.ips | uniq -u | $GITHUB_WORKSPACE/.github/scripts/clean_ips.sh > $GITHUB_WORKSPACE/all_botsonly.ips

      - name: Commit & push updated IP-Lists into this Repo
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          git add .
          git diff-index --quiet HEAD || git commit -m "Daily auto update of the IP-Lists" && git push

      - name: Ensure jq is available
        run: sudo apt-get update && sudo apt-get install -y jq

      # --- (1) CLEAR the list completely ---
      - name: Clear Cloudflare list (set to empty)
        id: cf_clear
        shell: bash
        env:
          CF_API: https://api.cloudflare.com/client/v4
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_LIST_ID: ${{ secrets.CF_LIST_ID }}
          CF_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          set -euo pipefail
          RESP=$(curl -sS -X PUT \
            -H "Authorization: Bearer ${CF_TOKEN}" \
            -H "Content-Type: application/json" \
            --data '[]' \
            "${CF_API}/accounts/${CF_ACCOUNT_ID}/rules/lists/${CF_LIST_ID}/items")
          echo "$RESP" | jq .
          OP_ID=$(echo "$RESP" | jq -r '.result.operation_id // empty')
          [ -n "$OP_ID" ] || { echo "No operation_id from clear"; exit 1; }
          echo "operation_id=${OP_ID}" >> "$GITHUB_OUTPUT"

      - name: Wait for Cloudflare clear op
        shell: bash
        env:
          CF_API: https://api.cloudflare.com/client/v4
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          OP_ID: ${{ steps.cf_clear.outputs.operation_id }}
        run: |
          set -euo pipefail
          for i in $(seq 1 60); do
            r=$(curl -sS -H "Authorization: Bearer ${CF_TOKEN}" \
              "${CF_API}/accounts/${CF_ACCOUNT_ID}/rules/lists/bulk_operations/${OP_ID}")
            status=$(echo "$r" | jq -r '.result.status // .status // "unknown"')
            echo "Clear op status: $status"
            case "$status" in
              completed) exit 0 ;;
              failed) echo "$r" | jq .; exit 1 ;;
            esac
            sleep 5
          done
          echo "Timed out waiting for clear operation ${OP_ID}"; exit 1

      # --- (2) Build CSV and DEDUPE across all files (merge comments) ---
      - name: Build consolidated CSV with list names
        shell: bash
        env:
          OUT_CSV: ${{ github.workspace }}/cloudflare_items.csv
        run: |
          set -euo pipefail
          echo "value,description" > "$OUT_CSV"
          shopt -s nullglob
          for f in "$GITHUB_WORKSPACE"/iplists-botsonly/*.ips; do
            name="$(basename "$f" .ips)"
            # each line ‚Üí value,description
            awk 'NF{gsub(/\r$/,""); print}' "$f" \
              | awk -v desc="$name" 'NF{print $0","desc}' >> "$OUT_CSV"
          done
          echo "CSV built: $OUT_CSV"

      - name: Convert CSV to JSON (robust; v4+v6, /32 & /128, validate, dedupe, merge comments)
        id: make_json
        shell: bash
        env:
           IN_CSV: ${{ github.workspace }}/cloudflare_items.csv
           IPS_DIR: ${{ github.workspace }}/iplists-botsonly
        run: |
            set -euo pipefail

            # ---- paths
            TMP_DIR="${RUNNER_TEMP:-/tmp}"
            mkdir -p "$TMP_DIR"
            STREAM="$TMP_DIR/stream.tsv"
            REJECTS="$TMP_DIR/rejected_ipv6_cidrs.txt"
            ITEMS="$TMP_DIR/items.json"
            JQ_ERR="$TMP_DIR/jq.err"
            : > "$STREAM"
            : > "$REJECTS"
            : > "$JQ_ERR"

            echo "üîé Input discovery‚Ä¶"
            echo "workspace=${GITHUB_WORKSPACE}"
            echo "CSV path: $IN_CSV"
            echo "IPS_DIR:  $IPS_DIR"

            echo "üìÅ Listing $IPS_DIR (if exists):"
            ls -lah "$IPS_DIR" || echo "(no directory)"

            # ---- Determine input mode; default to 'ips' to be safe with set -u
            INPUT_MODE="ips"
            if [[ -f "$IN_CSV" && $(wc -l < "$IN_CSV" || echo 0) -gt 1 ]]; then
            echo "‚úÖ Using CSV: $IN_CSV (lines: $(wc -l < "$IN_CSV"))"
            INPUT_MODE="csv"
            fi

            # ---- 1) Add rows from CSV if present (value,description[,...])
            if [[ "${INPUT_MODE:-ips}" == "csv" ]]; then
            tail -n +2 "$IN_CSV" || true \
            | awk -F, '
                {
                    val=$1; desc=$2;
                    for(i=3;i<=NF;i++) desc=desc","$i;
                    gsub(/\r$/,"",desc);
                    gsub(/^[ \t]+|[ \t]+$/,"",val);
                    gsub(/^[ \t]+|[ \t]+$/,"",desc);
                    gsub(/\t/, "", val);  # strip tabs (TSV safety)
                    gsub(/\t/, "", desc); # strip tabs
                    if (val!="") print val "\t" desc;
                }' >> "$STREAM"
            fi

            # ---- 2) Add rows from *.ips files (desc = filename)
            if [[ -d "$IPS_DIR" ]]; then
            shopt -s nullglob
            IPS_FILES=( "$IPS_DIR"/*.ips )
            echo "‚û°Ô∏è  Found ${#IPS_FILES[@]} .ips files"
            for f in "${IPS_FILES[@]}"; do
                name="$(basename "$f" .ips)"
                count=$(wc -l < "$f" || echo 0)
                echo "   - $name.ips ($count lines)"
                awk '
                { gsub(/\r$/,""); line=$0 }
                { sub(/^[ \t]+/, "", line); sub(/[ \t]+$/, "", line) }
                { sub(/[ \t]+#.*$/, "", line); if (line ~ /^#/) line="" }
                length(line)>0 { print line }
                ' "$f" \
                | awk -v desc="$name" '
                    NF{
                    gsub(/\t/, "", $0);      # strip tabs from value
                    gsub(/\t/, "", desc);    # strip tabs from desc
                    print $0 "\t" desc
                    }
                ' >> "$STREAM"
            done
            fi

            TOTAL_INPUTS=$(wc -l < "$STREAM" || echo 0)
            echo "üì¶ Candidates before validation: $TOTAL_INPUTS"
            if [[ "$TOTAL_INPUTS" -eq 0 ]]; then
            echo "‚ùå No candidate values to process."
            echo "üß™ Debug: top of CSV (if any):"; head -n 20 "$IN_CSV" || true
            exit 1
            fi

            # ---- 3) TSV -> JSON items (normalize, validate, dedupe) with guarded jq and error capture
            set +e
            jq -R '
            # IPv4 (optional CIDR)
            def ipv4: "^([0-9]{1,3}\\.){3}[0-9]{1,3}(?:/(?:[0-9]|[12][0-9]|3[0-2]))?$";
            # IPv6 (allow IPv4-mapped), optional CIDR; enforce v6 range later
            def ipv6_loose: "^[0-9A-Fa-f:.]+(?:/[0-9]{1,3})?$";
            # IPv6 prefix or null
            def v6_prefix:
                if test(".*/") then ( capture(".*/(?<p>[0-9]+)$").p | tonumber ) else null end;
            # reject zone index
            def has_zone: test("%");

            def classify($desc):
                if has_zone then
                {ip:., comment:$desc, ok:false, why:"ipv6_zone_index_not_allowed"}
                elif test(ipv4) then
                if contains("/") then {ip:., comment:$desc, ok:true}
                else {ip:(. + "/32"), comment:$desc, ok:true}  # bare IPv4 -> /32
                end
                elif test(ipv6_loose) then
                ( . as $ip
                    | ( $ip | ascii_downcase ) as $low
                    | ($low | v6_prefix) as $p
                    | if $p == null then
                        {ip:($low + "/128"), comment:$desc, ok:true}  # bare IPv6 -> /128
                    elif ($p >= 12 and $p <= 128) then
                        {ip:$low, comment:$desc, ok:true}
                    else
                        {ip:$low, comment:$desc, ok:false, why:("ipv6_cidr_prefix_"+($p|tostring)+"_lt12")}
                    end )
                else
                {ip:., comment:$desc, ok:false, why:"not_ipv4_or_ipv6"}
                end;

            [ inputs
                | select(length>0)
                | ( . / "\t" ) as $p
                | ($p[0] // "") as $v
                | ($p[1] // "") as $desc
                | ($v | gsub("\\s+"; "")) as $v2
                | ($v2 | classify($desc))
            ] as $objs

            | ( $objs
                | map(select(.ok == false))
                | map("REJECT\t" + .ip + "\t" + (.why // ""))
                | .[]?
                ) as $rej
            | if ($rej|length) > 0 then
                ( $rej | @text ) | . as $noop
                else empty end

            | $objs
            | map(select(.ok))
            | sort_by(.ip)
            | group_by(.ip)
            | map({
                ip: .[0].ip,
                comment: ( [.[].comment] | map(select(length>0)) | unique | join(", ") )
                })
            ' 2> >( (tee -a "$JQ_ERR" | grep "^REJECT" || true) | sed "s/^REJECT\t//" >> "$REJECTS" ) \
            < "$STREAM" \
            > "$ITEMS"
            jq_status=$?
            set -e

            if [[ $jq_status -ne 0 ]]; then
            echo "‚ùå jq failed with exit code $jq_status"
            echo "‚îÄ‚îÄ jq stderr (last 50 lines) ‚îÄ‚îÄ"; tail -n 50 "$JQ_ERR" || true
            echo "‚îÄ‚îÄ First 20 lines of $STREAM ‚îÄ‚îÄ"; head -n 20 "$STREAM" || true
            exit 1
            fi

            if [[ ! -s "$ITEMS" ]]; then
            echo "‚ùå ERROR: No valid items produced after validation."
            echo "üëÄ First 20 raw lines from $STREAM:"; head -n 20 "$STREAM" || true
            echo "üëÄ First 20 rejects (if any):"; head -n 20 "$REJECTS" || true
            exit 1
            fi

            echo "‚úÖ Unique items to upload: $(jq 'length' "$ITEMS")"
            if [ -s "$REJECTS" ]; then
            echo "‚ö†Ô∏è Some entries were rejected. First few:"; head -n 10 "$REJECTS" || true
            fi

            echo "items_json=$ITEMS" >> "$GITHUB_OUTPUT"
            echo "Preview:"; jq '.[0:5]' "$ITEMS"

      - name: Upload rejected IPv6 CIDRs as artifact (optional)
        if: always()
        uses: actions/upload-artifact@v4
        with:
            name: rejected-ipv6-cidrs
            path: ${{ runner.temp }}/rejected_ipv6_cidrs.txt
            if-no-files-found: ignore
          
      # --- (3) Upload unique items and wait for completion ---
      - name: Update Cloudflare list (replace all items)
        id: cf_put
        shell: bash
        env:
          CF_API: https://api.cloudflare.com/client/v4
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_LIST_ID: ${{ secrets.CF_LIST_ID }}
          CF_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          ITEMS_JSON: ${{ steps.make_json.outputs.items_json }}
        run: |
          set -euo pipefail
          RESP=$(curl -sS -X PUT \
            -H "Authorization: Bearer ${CF_TOKEN}" \
            -H "Content-Type: application/json" \
            --data @"${ITEMS_JSON}" \
            "${CF_API}/accounts/${CF_ACCOUNT_ID}/rules/lists/${CF_LIST_ID}/items")
          echo "$RESP" | jq .
          OP_ID=$(echo "$RESP" | jq -r '.result.operation_id // empty')
          [ -n "$OP_ID" ] || { echo "No operation_id returned"; echo "$RESP" | jq '.errors'; exit 1; }
          echo "operation_id=${OP_ID}" >> "$GITHUB_OUTPUT"

      - name: Wait for Cloudflare bulk operation
        shell: bash
        env:
          CF_API: https://api.cloudflare.com/client/v4
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          OP_ID: ${{ steps.cf_put.outputs.operation_id }}
        run: |
          set -euo pipefail
          for i in $(seq 1 60); do
            r=$(curl -sS -H "Authorization: Bearer ${CF_TOKEN}" \
              "${CF_API}/accounts/${CF_ACCOUNT_ID}/rules/lists/bulk_operations/${OP_ID}")
            status=$(echo "$r" | jq -r '.result.status // .status // "unknown"')
            echo "Bulk op status: $status"
            case "$status" in
              completed) exit 0 ;;
              failed) echo "$r" | jq .; exit 1 ;;
            esac
            sleep 5
          done
          echo "Timed out waiting for bulk operation ${OP_ID}"; exit 1